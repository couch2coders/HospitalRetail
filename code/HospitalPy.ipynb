{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f942d59e-576a-4496-acb1-7cc550e52a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install\n",
    "# !pip install mlxtend\n",
    "# !pip install transformers torch\n",
    "# !pip install transformers tensorflow\n",
    "# !pip install sentencepiece\n",
    "# !pip install transformers torch sentencepiece\n",
    "\n",
    "# \n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "from sklearn.cluster import KMeans\n",
    "# from sentence_transformers import SentenceTransforme\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('../data/Hospital_data_cleaned.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "775ef240-05a4-431e-858a-5f5cddc689b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HOSPITAL</th>\n",
       "      <th>PMT_GRP</th>\n",
       "      <th>SALES_DT</th>\n",
       "      <th>SALES_TM</th>\n",
       "      <th>CHECK_ID</th>\n",
       "      <th>TRANS_ID</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>ITEM_NM</th>\n",
       "      <th>GROSS_REV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOSPITAL A</td>\n",
       "      <td>CASH</td>\n",
       "      <td>2024-01-06</td>\n",
       "      <td>11:33:52</td>\n",
       "      <td>25374041</td>\n",
       "      <td>30720877</td>\n",
       "      <td>GRILL &amp; CO</td>\n",
       "      <td>1 TENDER</td>\n",
       "      <td>8.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOSPITAL A</td>\n",
       "      <td>CASH</td>\n",
       "      <td>2024-06-06</td>\n",
       "      <td>19:08:06</td>\n",
       "      <td>25872838</td>\n",
       "      <td>29838066</td>\n",
       "      <td>GRILL &amp; CO</td>\n",
       "      <td>1 TENDER</td>\n",
       "      <td>2.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOSPITAL A</td>\n",
       "      <td>CASH</td>\n",
       "      <td>2024-06-10</td>\n",
       "      <td>10:53:45</td>\n",
       "      <td>26109477</td>\n",
       "      <td>29853607</td>\n",
       "      <td>GRILL &amp; CO</td>\n",
       "      <td>1 TENDER</td>\n",
       "      <td>1.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOSPITAL A</td>\n",
       "      <td>CASH</td>\n",
       "      <td>2024-02-22</td>\n",
       "      <td>18:49:46</td>\n",
       "      <td>26223100</td>\n",
       "      <td>29703893</td>\n",
       "      <td>GRILL &amp; CO</td>\n",
       "      <td>1 TENDER</td>\n",
       "      <td>1.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOSPITAL A</td>\n",
       "      <td>CASH</td>\n",
       "      <td>2024-02-26</td>\n",
       "      <td>11:51:55</td>\n",
       "      <td>26267834</td>\n",
       "      <td>29705571</td>\n",
       "      <td>GRILL &amp; CO</td>\n",
       "      <td>1 TENDER</td>\n",
       "      <td>1.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     HOSPITAL PMT_GRP    SALES_DT  SALES_TM  CHECK_ID  TRANS_ID    CATEGORY  \\\n",
       "0  HOSPITAL A    CASH  2024-01-06  11:33:52  25374041  30720877  GRILL & CO   \n",
       "1  HOSPITAL A    CASH  2024-06-06  19:08:06  25872838  29838066  GRILL & CO   \n",
       "2  HOSPITAL A    CASH  2024-06-10  10:53:45  26109477  29853607  GRILL & CO   \n",
       "3  HOSPITAL A    CASH  2024-02-22  18:49:46  26223100  29703893  GRILL & CO   \n",
       "4  HOSPITAL A    CASH  2024-02-26  11:51:55  26267834  29705571  GRILL & CO   \n",
       "\n",
       "    ITEM_NM  GROSS_REV  \n",
       "0  1 TENDER       8.94  \n",
       "1  1 TENDER       2.98  \n",
       "2  1 TENDER       1.49  \n",
       "3  1 TENDER       1.49  \n",
       "4  1 TENDER       1.49  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3176c302-98b6-4ae0-8ace-0e31a5a34f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HOSPITAL      object\n",
       "PMT_GRP       object\n",
       "SALES_DT      object\n",
       "SALES_TM      object\n",
       "CHECK_ID       int64\n",
       "TRANS_ID       int64\n",
       "CATEGORY      object\n",
       "ITEM_NM       object\n",
       "GROSS_REV    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089b6ca6-30df-4dd3-ab13-098171d7feae",
   "metadata": {},
   "source": [
    "# NLP\n",
    "\n",
    "Use NLP method to classify food items into categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "10df4ace-61b2-49b2-8cab-584657b52ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_agg = (\n",
    "    df[df['SALES_DT'] < '2024-04-01']\n",
    "    .groupby('ITEM_NM')['SALES_DT']\n",
    "    .nunique()\n",
    "    .reset_index(name='distinct_sales_dates')\n",
    "    .query('distinct_sales_dates > 10')\n",
    ")\n",
    "valid_items = item_agg['ITEM_NM']\n",
    "df['FREQ_SELLER'] = df['ITEM_NM'].isin(valid_items).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "635159c4-2fed-4887-84fb-9340ac0beca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>GROSS_REV</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOSPITAL</th>\n",
       "      <th>is_valid_item</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">HOSPITAL A</th>\n",
       "      <th>0</th>\n",
       "      <td>57451.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1144862.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">HOSPITAL B</th>\n",
       "      <th>0</th>\n",
       "      <td>42633.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1291891.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           GROSS_REV\n",
       "HOSPITAL   is_valid_item            \n",
       "HOSPITAL A 0                57451.73\n",
       "           1              1144862.99\n",
       "HOSPITAL B 0                42633.66\n",
       "           1              1291891.06"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## only classify if item has sold on at least 3 separate occasions\n",
    "# df[['GROSS_REV','is_valid_item','HOSPITAL']].groupby(['HOSPITAL','is_valid_item']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e1fea658-da4e-4368-8d0d-59da38c9adb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean item names to only include letters (no symbols/letters)\n",
    "#1386 unique items\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "cleaned = df_filtered['ITEM_NM'].apply(clean_text)\n",
    "# vectorizer = TfidfVectorizer(stop_words='english')\n",
    "# X = vectorizer.fit_transform(cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8b3dce9a-fb8d-4d4e-b1db-da28d61c27fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8a777c8c-7132-421d-a7cb-e9290c14b743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1410"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ITEM_NM'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b8a3bdd5-b0b2-4a5b-ab41-169e9a49a6b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1410"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ITEM_NM'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6743228-1504-4585-a1c4-97b84321af30",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = [word_tokenize(item.lower()) for item in cleaned.unique()]\n",
    "\n",
    "# Train Word2Vec\n",
    "model = Word2Vec(sentences=tokenized, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "\n",
    "#model.wv checks if a given word is in the Word2Vec model\n",
    "#once it is validated to be in the model, model.wv[word] assigns its vectorization\n",
    "#if the word does not exist in the model it is assigned zero\n",
    "\n",
    "def get_avg_vector(tokens, model):\n",
    "    vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
    "    return np.mean(vectors, axis=0) if vectors else np.zeros(model.vector_size)\n",
    "\n",
    "#creates a vector value for each food item in our tokenized word set\n",
    "sentence_vectors = [get_avg_vector(item, model) for item in tokenized]\n",
    "\n",
    "#initializing model\n",
    "kmeans = KMeans(n_clusters=10, random_state=0)\n",
    "clusters = kmeans.fit_predict(sentence_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5ff4d5-3488-406e-8a78-087a8c4e0305",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42feeb7f-2e1d-41ec-90d3-a1332ccb2f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_nlp = pd.DataFrame({\n",
    "    'food_item': cleaned.unique(),\n",
    "    'cluster': clusters\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c973eff-b1c8-4b6b-b6e0-e7477786e369",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4d05ba-45a5-4125-9948-eaf171d4f9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nlp\n",
    "df_nlp.to_csv('food_cluster.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f18c2df-a2d2-4fe6-94bd-38d45ef0a4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "candidate_labels = [\"Beverage\", \"Dessert\", \"Sandwich\", \"Breakfast\", \"Salad\"]\n",
    "\n",
    "result = classifier(\"egg and cheese bagel\", candidate_labels)\n",
    "print(result[\"labels\"][0])  # Best match\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cb8f70-98eb-41f9-875e-ba7acbef782b",
   "metadata": {},
   "source": [
    "# Optimization\n",
    "\n",
    "We assume Beverages make 35% more than Food"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0999a77-12af-4fe6-8288-accfd71aba68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c5d14fb-5070-4bc7-8215-a6981218fb31",
   "metadata": {},
   "source": [
    "# Purchasing Habits\n",
    "    - PURCHASING HABITS (TIME OF DAY, PRODUCT MIX, SEASONAILITY)\n",
    "        - REVIEW FOR HOLIDAYS/HIGHEST HOSPITALIZATION TIMES\n",
    "        - DAY SEASONALITY/MONTH SEASONALITY\n",
    "        - COMPLIMENTARY GOODS/SUBSTITUTE\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df380891-1427-44dc-a88e-7f64f5ae8a34",
   "metadata": {},
   "source": [
    "### Seasonality\n",
    "\n",
    "We see high levels of seasonality at various levels of detail (monthly; weekly; minute)\n",
    "\n",
    "We also find either seasonality or trend by category type, many categories may appear to have trend in the short run but turn seasonal as more data populates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa10ade5-bc00-454d-916b-14ac39bacf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we see high level of weekly seasonality\n",
    "# we see monthly seasonality\n",
    "# we see minute seasonality\n",
    "# hourly seasonality is less impactful\n",
    "# some categories experience trend, unable to validate if seasonality vs trend due to time horizon\n",
    "df['MONTH'] = pd.to_datetime(df['SALES_DT']).dt.month \n",
    "df['HR_MIN'] = pd.to_datetime(df['SALES_TM'], format='%H:%M:%S').dt.strftime('%H:%M')\n",
    "df['HR'] = pd.to_datetime(df['SALES_TM'], format='%H:%M:%S').dt.strftime('%H')\n",
    "df[['SALES_DT','TRANS_ID']].groupby('SALES_DT').count().plot()\n",
    "df[['MONTH','TRANS_ID']].groupby('MONTH').count().plot()\n",
    "df[['HR_MIN','TRANS_ID']].groupby('HR_MIN').count().plot()\n",
    "df[['HR','TRANS_ID']].groupby('HR').count().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392a5482-7900-4e98-91b5-c36637d83e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract month\n",
    "df['MONTH'] = pd.to_datetime(df['SALES_DT']).dt.month\n",
    "\n",
    "# Loop through each category\n",
    "for category in df['CATEGORY'].unique():\n",
    "    subset = df[df['CATEGORY'] == category]\n",
    "\n",
    "    # Group by month and count transactions\n",
    "    monthly_counts = subset.groupby('MONTH')['TRANS_ID'].count()\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    monthly_counts.plot(kind='line')\n",
    "    plt.title(f'Transactions by Month - {category}')\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('Transaction Count')\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ee3877-ab27-49d9-8c42-8a53a96b6857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have a long tail by category\n",
    "# most categories have < 25k transactions\n",
    "# most checks have < 5 items on it\n",
    "\n",
    "\n",
    "# Group by CATEGORY and HOSPITAL and count transactions\n",
    "grouped = df.groupby(['CATEGORY', 'HOSPITAL'])['TRANS_ID'].count().unstack().fillna(0)\n",
    "\n",
    "# Sort categories by total transaction count\n",
    "grouped = grouped.loc[grouped.sum(axis=1).sort_values(ascending=False).index]\n",
    "\n",
    "# Plot grouped bar chart\n",
    "grouped.plot(kind='bar', figsize=(10, 6))\n",
    "\n",
    "plt.title('Transactions per Category by Hospital')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Transaction Count')\n",
    "plt.legend(title='Hospital', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# df[['CATEGORY','TRANS_ID']].groupby('CATEGORY').count().sort_values(by = 'TRANS_ID', ascending = False).plot(kind = 'bar')\n",
    "df[['CHECK_ID','TRANS_ID']].groupby('CHECK_ID').count().hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3491043-1ac8-4f7c-951f-8e0da364d69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find number of items by check id along with total revnue\n",
    "agg1 = df.groupby('CHECK_ID').agg(\n",
    "    TRANS_COUNT=('TRANS_ID', 'count'),\n",
    "    TOTAL_REV=('GROSS_REV', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# by trans count find average rev\n",
    "\n",
    "agg1[['TRANS_COUNT','TOTAL_REV']].groupby('TRANS_COUNT').agg(\n",
    "    TOTAL_REV = ('TOTAL_REV','sum')\n",
    "    ,AVG_REV = ('TOTAL_REV','mean')\n",
    "    ,N_TRANS = ('TRANS_COUNT','sum')\n",
    ").reset_index().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fd6d99-963b-48ef-baaf-a8315271bb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[['CATEGORY','TRANS_ID']].groupby('CATEGORY').count().reset_index().sort_values(by = 'TRANS_ID')\n",
    "\n",
    "df[['CATEGORY','TRANS_ID']].groupby('CATEGORY').count().reset_index().sort_values(by = 'TRANS_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8161f9-209f-4c4d-9ec2-a3c95996fa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a binary basket format: 1 if item is in the check\n",
    "basket = df.groupby(['CHECK_ID', 'ITEM_NM'])['ITEM_NM'].count().unstack().fillna(0)\n",
    "basket = basket.applymap(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a337ea1c-08ac-4672-8dba-aa67f66ce5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Find frequent itemsets\n",
    "frequent_itemsets = apriori(basket, min_support=0.01, use_colnames=True)\n",
    "\n",
    "# Generate rules (optional)\n",
    "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1.0)\n",
    "\n",
    "# Top item combinations\n",
    "print(frequent_itemsets.sort_values(by='support', ascending=False).head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
